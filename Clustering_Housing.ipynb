{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Clustering-Housing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norruljannah/Exercise/blob/main/Clustering_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXpXpPUcViRs"
      },
      "source": [
        "# Import software libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7SloSpViRz",
        "outputId": "326ff443-bbfa-46ec-ea0a-9911c01bd469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys                                             # Read system parameters.\n",
        "import os                                              # Interact with the operating system.\n",
        "import numpy as np                                     # Work with multi-dimensional arrays and matrices.\n",
        "import pandas as pd                                    # Manipulate and analyze data.\n",
        "import matplotlib                                      # Create 2D charts.\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import folium                                          # Plot values on a map.\n",
        "import yellowbrick                                     # Visualize elbow and silhouette plots.\n",
        "import sklearn                                         # Perform data mining and analysis.\n",
        "from time import time                                  # Calculate training time.\n",
        "\n",
        "# Summarize software libraries used.\n",
        "print('Libraries used in this project:')\n",
        "print('- Python {}'.format(sys.version))\n",
        "print('- NumPy {}'.format(np.__version__))\n",
        "print('- pandas {}'.format(pd.__version__))\n",
        "print('- Matplotlib {}'.format(matplotlib.__version__))\n",
        "print('- Folium {}'.format(folium.__version__))\n",
        "print('- Yellowbrick {}'.format(yellowbrick.__version__))\n",
        "print('- scikit-learn {}\\n'.format(sklearn.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries used in this project:\n",
            "- Python 3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "- NumPy 1.19.5\n",
            "- pandas 1.1.5\n",
            "- Matplotlib 3.2.2\n",
            "- Folium 0.8.3\n",
            "- Yellowbrick 0.9.1\n",
            "- scikit-learn 0.22.2.post1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPUGI9XpGMTP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtAuNWT9ViR2"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeZ69xqJViR3"
      },
      "source": [
        "PROJECT_ROOT_DIR = '.'\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'housing_data')\n",
        "print('Data files in this project:', os.listdir(DATA_PATH) )\n",
        "\n",
        "# Read the raw dataset.\n",
        "housing_data_file = os.path.join( DATA_PATH, 'kc_house_data.csv' )\n",
        "housing_data = pd.read_csv( housing_data_file )\n",
        "print('Loaded {} records from {}.\\n'.format(len(housing_data), housing_data_file))\n",
        "print(f'Dataset Rows and Columns: {housing_data.shape}')\n",
        "\n",
        "# Preview first 5 records in the dataset.\n",
        "housing_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCFbZn6EViR4"
      },
      "source": [
        "# Engineer features as needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "070VFEAXViR4"
      },
      "source": [
        "# Create a price per square foot feature based on 'price' and 'sqft_living'.\n",
        "housing_data['price_per_sqft'] = housing_data['price'] / housing_data['sqft_living']\n",
        "housing_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmTGORh8ViR5"
      },
      "source": [
        "# Use a *k*-means model to label every row in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqZVgbzJViR7"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Produce cluster labels.\n",
        "def get_cluster_labels(cluster_count, X):\n",
        "    \n",
        "    kmeans = KMeans(n_clusters = cluster_count,\n",
        "                    init = 'k-means++',\n",
        "                    random_state = 42)\n",
        "    \n",
        "    kmeans.fit(X)\n",
        "    cluster_labels = kmeans.predict(X)\n",
        "    \n",
        "    # Return the original DataFrame with the labels appended as a new column.\n",
        "    return cluster_labels\n",
        "\n",
        "print('The function to produce cluster labels using a k-means model has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMMOt0P-ViR7"
      },
      "source": [
        "# Generate the cluster labels and attach them to the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ye2SNr_ViR9"
      },
      "source": [
        "# Initially cluster by latitude and longitude, just to verify we're using k-means model correctly.\n",
        "feature_set_1 = ['lat', 'long']\n",
        "X = housing_data[feature_set_1]\n",
        "\n",
        "# Generate cluster labels for the housing data, assuming 4 clusters.\n",
        "cluster_labels = get_cluster_labels(4, X)\n",
        "\n",
        "# Append the cluster labels to a new column in the original dataset.\n",
        "labeled_houses = housing_data.assign(c_label = cluster_labels)\n",
        "\n",
        "# Show a preview of rows in the dataset with cluster labels added.\n",
        "labeled_houses.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnQJRLQ3ViR-"
      },
      "source": [
        "# Observe how many houses were distributed to each cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ClunD-uCViR-"
      },
      "source": [
        "for i in range(4):\n",
        "    num_in_clust = len(labeled_houses[labeled_houses['c_label'] == i])\n",
        "    print('Number of houses in cluster {} = {}'.format(i, num_in_clust))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhPpA-eoViSA"
      },
      "source": [
        "# Show clusters of homes on the map by location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiAFcurmViSA"
      },
      "source": [
        "from folium.plugins import HeatMap\n",
        "\n",
        "def show_on_map(labeled_house_dataset, map_title):\n",
        "    \n",
        "    # To avoid overwhelming the visualization tool, we'll only plot every nth house.\n",
        "    n_homes = 20\n",
        "    mapping_set = labeled_house_dataset.sort_values(by = ['price'], ascending = False)[::n_homes]\n",
        "\n",
        "    # Descriptions of the building grades used in King County.\n",
        "    bldg_grades = ['Unknown', 'Cabin', 'Substandard', 'Poor', 'Low', 'Fair',\n",
        "                   'Low Average', 'Average', 'Good', 'Better',\n",
        "                   'Very Good', 'Excellent', 'Luxury', 'Mansion', 'Exceptional Properties']\n",
        "\n",
        "    # Generate the base map, centering on King County.\n",
        "    base_map = folium.Map(location = [47.5300, -122.2000],\n",
        "                          control_scale = True, \n",
        "                          max_zoom = 20,\n",
        "                          zoom_start = 10,\n",
        "                          zoom_control = True)\n",
        "\n",
        "    # Get price of most expensive house.\n",
        "    max_price = labeled_house_dataset.loc[labeled_house_dataset['price'].idxmax()]['price']\n",
        "\n",
        "    # Plot homes by price.\n",
        "    for index, row in mapping_set.iterrows():\n",
        "\n",
        "        # Add popup text. Click each point to show details.\n",
        "        popup_text = '<br>'.join(['King&nbsp;County&nbsp;Housing&nbsp;Sales&nbsp;Data',\n",
        "                                  'Price:&nbsp;${:,.0f}',\n",
        "                                  'Cluster:&nbsp;{:.0f}',\n",
        "                                  'Bedrooms:&nbsp;{:.0f}',\n",
        "                                  'Bathrooms:&nbsp;{:.0f}',\n",
        "                                  'Sqft&nbsp;Living:&nbsp;{:,.0f}',\n",
        "                                  'Location:&nbsp;[{:.3f},{:.3f}]'])\n",
        "\n",
        "        popup_text = popup_text.format(row['price'],\n",
        "                                       row['c_label'],\n",
        "                                       row['bedrooms'],\n",
        "                                       row['bathrooms'],\n",
        "                                       row['sqft_living'],\n",
        "                                       row['lat'],\n",
        "                                       row['long'])\n",
        "\n",
        "        cluster_value = int(row['c_label'])\n",
        "        scaling_value = (row['price'] / max_price)      # 1.0 for highest price.\n",
        "\n",
        "        folium.CircleMarker([row['lat'], row['long']],\n",
        "                            radius = 25 * scaling_value,\n",
        "                            weight = 3,\n",
        "                            fill = True,\n",
        "                            fill_color = '#000000',\n",
        "                            color = '#0000FF',\n",
        "                            fill_opacity = 0.8,\n",
        "                            opacity = 0.8,\n",
        "                            popup = popup_text).add_to(base_map)\n",
        "        \n",
        "    # Heat map around each cluster.\n",
        "    cluster_max = labeled_house_dataset.loc[labeled_house_dataset['c_label'].idxmax()]['c_label'] + 1\n",
        "    \n",
        "    for cluster_num in range(0, cluster_max):\n",
        "        \n",
        "        houses_in_same_cluster = labeled_house_dataset.loc[labeled_house_dataset['c_label'] == cluster_num]\n",
        "        house_locations = houses_in_same_cluster[['lat', 'long']].copy()\n",
        "        \n",
        "        mean_price = houses_in_same_cluster['price_per_sqft'].mean()\n",
        "        \n",
        "        cluster_name = f'Cluster {cluster_num} (mean ${mean_price:,.0f} per sqft)'\n",
        "        feature_group = folium.FeatureGroup(name = cluster_name)\n",
        "        feature_group.add_child(HeatMap(house_locations, radius = 10))\n",
        "        base_map.add_child(feature_group)\n",
        "        \n",
        "    folium.map.LayerControl('bottomright', collapsed = False).add_to(base_map)\n",
        "    \n",
        "    # Add title to map.\n",
        "    map_html = f'<div style=\"position:fixed; top:10px; left:60px; z-index:9999\"><b>{map_title}</b></div>'\n",
        "    base_map.get_root().html.add_child(folium.Element(map_html))\n",
        "\n",
        "    return base_map\n",
        "\n",
        "print('The function to show the map has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqGqYIljViSC"
      },
      "source": [
        "# View the results on the map.\n",
        "show_on_map(labeled_houses, 'Houses clustered by location')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHwm1eJ-ViSC"
      },
      "source": [
        "# Cluster by price per square foot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "v388qLPYViSD"
      },
      "source": [
        "# Cluster homes by the price per square foot.\n",
        "feature_set_2 = ['price_per_sqft']\n",
        "X = housing_data[feature_set_2]\n",
        "\n",
        "# Generate cluster labels for the housing data, assuming 4 clusters.\n",
        "cluster_labels = get_cluster_labels(4, X)\n",
        "\n",
        "# Append the cluster labels to a new column in the original dataset.\n",
        "labeled_houses = housing_data.assign(c_label = cluster_labels)\n",
        "\n",
        "# Show on the map.\n",
        "show_on_map(labeled_houses, 'Houses clustered by price per square foot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwdZYBB3ViSD"
      },
      "source": [
        "# Prepare to cluster by multiple features of interest to customers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-uOkzjebViSD"
      },
      "source": [
        "# Specify the new dataset.\n",
        "final_feature_set = ['sqft_living', 'bathrooms', 'bedrooms', 'grade', 'view', 'waterfront']        \n",
        "X = housing_data[final_feature_set] \n",
        "\n",
        "print('A dataset containing features of interest to customers has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5L7soe0ViSE"
      },
      "source": [
        "# Use the elbow method to determine the optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvz1LrodViSF"
      },
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Use the elbow method to find the optimal number of clusters.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 7)\n",
        "\n",
        "visualizer = KElbowVisualizer(KMeans(init = 'k-means++', random_state = 42), k = (1, 10))\n",
        "visualizer.fit(X)\n",
        "visualizer.poof();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMdw6JTuViSF"
      },
      "source": [
        "# Use silhouette analysis to determine the optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5mkZbc3QViSF"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import silhouette_samples\n",
        "\n",
        "# The number of clusters to try out.\n",
        "range_n_clusters = [2, 3, 4, 5]\n",
        "\n",
        "high_score = 0\n",
        "optimum_n_clusters = 0\n",
        "\n",
        "for n in range_n_clusters:\n",
        "        \n",
        "    # Create k-means model and generate labels from the dataset.\n",
        "    kmeans = KMeans(n_clusters = n, random_state = 10)\n",
        "    cluster_labels = kmeans.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    \n",
        "    print('\\nWith {} clusters:'.format(n))\n",
        "    print('   - Average silhouette score:', silhouette_avg)\n",
        "    \n",
        "    # Note the high score.\n",
        "    if silhouette_avg > high_score:\n",
        "        high_score = silhouette_avg\n",
        "        optimum_n_clusters = n\n",
        "\n",
        "    # Compute the silhouette scores for each sample.\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "    \n",
        "    # Prepare to plot charts side by side.\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(17, 5)\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    ax1.set_ylim([0, len(X) + (n + 1) * 10])\n",
        "    y_lower = 10\n",
        "    \n",
        "    # LEFT SIDE: SILHOUETTE PLOTS\n",
        "    for i in range(n):\n",
        "        \n",
        "        # Plot silhouette for one cluster at a time.\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        color = cm.nipy_spectral(float(i) / n)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0,\n",
        "                          ith_cluster_silhouette_values,\n",
        "                          facecolor = color,\n",
        "                          edgecolor = color,\n",
        "                          alpha = 1)\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "        y_lower = y_upper + 10  # Use 10 for the 0 samples.\n",
        "        \n",
        "        # Log how many values were in this cluster.\n",
        "        print('   - Cluster {} includes {} values.'.format(i, size_cluster_i))\n",
        "\n",
        "    ax1.set_title('Silhouette Plots')\n",
        "    ax1.set_xlabel('Silhouette Coefficient Values')\n",
        "    ax1.set_ylabel('Cluster Label')\n",
        "    ax1.axvline(x = silhouette_avg, color = 'red', linestyle = '--')\n",
        "    ax1.set_yticks([])\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # RIGHT SIDE: SCATTER PLOTS\n",
        "    \n",
        "    # Caption the various clusters.\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n)\n",
        "    centers = kmeans.cluster_centers_\n",
        "    \n",
        "    # Plot the first two features.\n",
        "    ax2.scatter(X['sqft_living'],\n",
        "                X['bathrooms'], \n",
        "                marker = 'o', \n",
        "                alpha = 0.7, \n",
        "                s = 50,\n",
        "                color = colors,\n",
        "                edgecolor = 'black');\n",
        "    \n",
        "    # Show a box at the center of each cluster, with the cluster number inside it.\n",
        "    ax2.scatter(centers[:, 0],centers[:, 1],marker = 's', c = 'white', alpha = 1.0, s = 200, edgecolor = 'black')\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker = '$%d$' % i, alpha = 1.0, s = 50, edgecolor = 'black')\n",
        "        \n",
        "    # Axis labels.\n",
        "    ax2.set_title('Clustered Data')\n",
        "    ax2.set_xlabel(X.columns[0])\n",
        "    ax2.set_ylabel(X.columns[1])\n",
        "    plt.suptitle(('Number of clusters = %d' % n), fontsize = 16, fontweight = 'bold')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('The highest score ({}) was obtained using {} centers.'.format(high_score, optimum_n_clusters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsklsJu9ViSG"
      },
      "source": [
        "# Use the optimal number of clusters to show the house groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8YyWZVXSViSG"
      },
      "source": [
        "# Generate cluster labels for the housing data based on the optimal number of clusters.\n",
        "cluster_labels = get_cluster_labels(optimum_n_clusters, X)\n",
        "\n",
        "# Append the cluster labels to a new column in the original dataset.\n",
        "labeled_houses = housing_data.assign(c_label = cluster_labels)\n",
        "\n",
        "# Show on the map\n",
        "show_on_map(labeled_houses, 'Houses clustered by size, grade, view, waterfront')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcTtySevViSH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}